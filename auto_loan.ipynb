{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, KBinsDiscretizer, LabelEncoder, MinMaxScaler, PowerTransformer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 06:58:55,100 : INFO : data loading...\n"
     ]
    }
   ],
   "source": [
    "logging.info('data loading...')\n",
    "train = pd.read_csv('auto_train.csv')\n",
    "test = pd.read_csv('auto_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、特征工程\n",
    "## 2.1 构造特征\n",
    "针对训练集、测试集：\n",
    "\n",
    "根据业务理解，计算新的特征；\n",
    "对某些比例特征进行等宽分箱（cut），对某些数值特征进行等频分箱（qcut），还有一些数值特征进行自定义分箱，划分bin的范围；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new_feats(train, test):\n",
    "    '''生成新特征：如年利率/分箱等特征'''\n",
    "    # Step 1: 合并训练集和测试集\n",
    "    data = pd.concat([train, test])\n",
    "\n",
    "    # Step 2: 具体特征工程\n",
    "    # 计算二级账户的年利率\n",
    "    data['sub_Rate'] = (data['sub_account_monthly_payment'] * data['sub_account_tenure'] - data[\n",
    "        'sub_account_sanction_loan']) / data['sub_account_sanction_loan']\n",
    "\n",
    "    # 计算主账户的年利率\n",
    "    data['main_Rate'] = (data['main_account_monthly_payment'] * data['main_account_tenure'] - data[\n",
    "        'main_account_sanction_loan']) / data['main_account_sanction_loan']\n",
    "\n",
    "    # 对部分特征进行分箱操作\n",
    "    # 等宽分箱\n",
    "    loan_to_asset_ratio_labels = [i for i in range(10)]\n",
    "    data['loan_to_asset_ratio_bin'] = pd.cut(data[\"loan_to_asset_ratio\"], 10, labels=loan_to_asset_ratio_labels)\n",
    "    # 等频分箱\n",
    "    data['asset_cost_bin'] = pd.qcut(data['asset_cost'], 10, labels=loan_to_asset_ratio_labels)\n",
    "    # 自定义分箱\n",
    "    amount_cols = [\n",
    "                   'total_monthly_payment',\n",
    "                   'main_account_sanction_loan',\n",
    "                   'main_account_disbursed_loan',\n",
    "                   'sub_account_sanction_loan',\n",
    "                   'sub_account_disbursed_loan',\n",
    "                   'main_account_monthly_payment',\n",
    "                   'sub_account_monthly_payment',\n",
    "                   'total_sanction_loan'\n",
    "                ]\n",
    "    amount_labels = [i for i in range(10)]\n",
    "    for col in amount_cols:\n",
    "        total_monthly_payment_bin = [-1, 5000, 10000, 30000, 50000, 100000, 300000, 500000, 1000000, 3000000, data[col].max()]\n",
    "        data[col + '_bin'] = pd.cut(data[col], total_monthly_payment_bin, labels=amount_labels).astype(int)\n",
    "\n",
    "    # Step 3: 返回包含新特征的训练集 & 测试集\n",
    "    return data[data['loan_default'].notnull()], data[data['loan_default'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 编码-Target Encoding\n",
    "Target encoding是一种结合目标值进行特征编码的方式。\n",
    "\n",
    "在二分类中，对于特征i，target encoding在该特征取值为k时的编码值为类别k对应的目标值期望E(y|xi=xik)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target_encoding_feats(train, test, encode_cols, target_col, n_fold=10):\n",
    "    '''生成target encoding特征'''\n",
    "    # for training set - cv\n",
    "    tg_feats = np.zeros((train.shape[0], len(encode_cols)))\n",
    "    kfold = StratifiedKFold(n_splits=n_fold, random_state=1024, shuffle=True)\n",
    "    for _, (train_index, val_index) in enumerate(kfold.split(train[encode_cols], train[target_col])):\n",
    "        df_train, df_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        for idx, col in enumerate(encode_cols):\n",
    "            target_mean_dict = df_train.groupby(col)[target_col].mean()\n",
    "            df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
    "            tg_feats[val_index, idx] = df_val[f'{col}_mean_target'].values\n",
    "\n",
    "    for idx, encode_col in enumerate(encode_cols):\n",
    "        train[f'{encode_col}_mean_target'] = tg_feats[:, idx]\n",
    "\n",
    "    # for testing set\n",
    "    for col in encode_cols:\n",
    "        target_mean_dict = train.groupby(col)[target_col].mean()\n",
    "        test[f'{col}_mean_target'] = test[col].map(target_mean_dict)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 近邻欺诈特征\n",
    "对于风控账户来说，存在风险的账户可能存在同批大量的注册情况，所以id可能是连着的。\n",
    "这里构建了近邻欺诈特征，就是每个账号的前后10个账户的lable取均值，也就代表着概率，意为可能违约账户聚集的概率，在一定程度上代表该账户可能违约的相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_neighbor_feats(train, test):\n",
    "    '''产生近邻欺诈特征'''\n",
    "    if not os.path.exists('../user_data/neighbor_default_probs.pkl'):\n",
    "        # 该特征需要跑的时间较久，因此将其存成了pkl文件\n",
    "        neighbor_default_probs = []\n",
    "        for i in tqdm(range(train.customer_id.max())):\n",
    "            if i >= 10 and i < 199706:\n",
    "                customer_id_neighbors = list(range(i - 10, i)) + list(range(i + 1, i + 10))\n",
    "            elif i < 199706:\n",
    "                customer_id_neighbors = list(range(0, i)) + list(range(i + 1, i + 10))\n",
    "            else:\n",
    "                customer_id_neighbors = list(range(i - 10, i)) + list(range(i + 1, 199706))\n",
    "\n",
    "            customer_id_neighbors = [customer_id_neighbor for customer_id_neighbor in customer_id_neighbors if\n",
    "                                     customer_id_neighbor in train.customer_id.values.tolist()]\n",
    "            neighbor_default_prob = train.set_index('customer_id').loc[customer_id_neighbors].loan_default.mean()\n",
    "            neighbor_default_probs.append(neighbor_default_prob)\n",
    "\n",
    "        df_neighbor_default_prob = pd.DataFrame({'customer_id': range(0, train.customer_id.max()),\n",
    "                                                 'neighbor_default_prob': neighbor_default_probs})\n",
    "        save_pkl(df_neighbor_default_prob, '../user_data/neighbor_default_probs.pkl')\n",
    "    else:\n",
    "        df_neighbor_default_prob = load_pkl('../user_data/neighbor_default_probs.pkl')\n",
    "    train = pd.merge(left=train, right=df_neighbor_default_prob, on='customer_id', how='left')\n",
    "    test = pd.merge(left=test, right=df_neighbor_default_prob, on='customer_id', how='left')\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 特征工程结果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_ENCODING_FETAS = [\n",
    "                            'employment_type',\n",
    "                             'branch_id',\n",
    "                             'supplier_id',\n",
    "                             'manufacturer_id',\n",
    "                             'area_id',\n",
    "                             'employee_code_id',\n",
    "                             'asset_cost_bin'\n",
    "                         ]\n",
    "\n",
    "\n",
    "# 特征工程\n",
    "logging.info('feature generating...')\n",
    "train, test = gen_new_feats(train, test)\n",
    "train, test = gen_target_encoding_feats(train, test, TARGET_ENCODING_FETAS, target_col='loan_default', n_fold=10)\n",
    "train, test = gen_neighbor_feats(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征的后续处理，比如一些转换后特征的数据类型转换，一些率值特征的简化，方便后续的模型学习，增强模型的鲁棒性。\n",
    "# 保存的最终特征名称列表\n",
    "SAVE_FEATS = [                 'customer_id',                 'neighbor_default_prob',                 'disbursed_amount',                 'asset_cost',                 'branch_id',                 'supplier_id',                 'manufacturer_id',                 'area_id',                 'employee_code_id',                 'credit_score',                 'loan_to_asset_ratio',                 'year_of_birth',                 'age',                 'sub_Rate',                 'main_Rate',                 'loan_to_asset_ratio_bin',                 'asset_cost_bin',                 'employment_type_mean_target',                 'branch_id_mean_target',                 'supplier_id_mean_target',                 'manufacturer_id_mean_target',                 'area_id_mean_target',                 'employee_code_id_mean_target',                 'asset_cost_bin_mean_target',                 'credit_history',                 'average_age',                 'total_disbursed_loan',                 'main_account_disbursed_loan',                 'total_sanction_loan',                 'main_account_sanction_loan',                 'active_to_inactive_act_ratio',                 'total_outstanding_loan',                 'main_account_outstanding_loan',                 'Credit_level',                 'outstanding_disburse_ratio',                 'total_account_loan_no',                 'main_account_tenure',                 'main_account_loan_no',                 'main_account_monthly_payment',                 'total_monthly_payment',                 'main_account_active_loan_no',                 'main_account_inactive_loan_no',                 'sub_account_inactive_loan_no',                 'enquirie_no',                 'main_account_overdue_no',                 'total_overdue_no',                 'last_six_month_defaulted_no'            ]\n",
    "\n",
    "\n",
    "# 特征工程 后处理\n",
    "# 简化特征\n",
    "for col in ['sub_Rate', 'main_Rate', 'outstanding_disburse_ratio']:\n",
    "     train[col] = train[col].apply(lambda x: 1 if x > 1 else x)\n",
    "     test[col] = test[col].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "# 数据类型转换\n",
    "train['asset_cost_bin'] = train['asset_cost_bin'].astype(int)\n",
    "test['asset_cost_bin'] = test['asset_cost_bin'].astype(int)\n",
    "train['loan_to_asset_ratio_bin'] = train['loan_to_asset_ratio_bin'].astype(int)\n",
    "test['loan_to_asset_ratio_bin'] = test['loan_to_asset_ratio_bin'].astype(int)\n",
    "\n",
    "# 存储包含新特征的数据集\n",
    "logging.info('new data saving...')\n",
    "cols = SAVE_FEATS + ['loan_default', ]\n",
    "train[cols].to_csv('./train_final.csv', index=False)\n",
    "test[cols].to_csv('./test_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_kfold(X_train, y_train, X_test, n_fold=5):\n",
    "    '''train lightgbm with k-fold split'''\n",
    "    gbms = []\n",
    "    kfold = StratifiedKFold(n_splits=n_fold, random_state=1024, shuffle=True)\n",
    "    oof_preds = np.zeros((X_train.shape[0],))\n",
    "    test_preds = np.zeros((X_test.shape[0],))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "        logging.info(f'############ fold {fold} ###########')\n",
    "        X_tr, X_val, y_tr, y_val = X_train.iloc[train_index], X_train.iloc[val_index], y_train[train_index], y_train[val_index]\n",
    "        dtrain = lgb.Dataset(X_tr, y_tr)\n",
    "        dvalid = lgb.Dataset(X_val, y_val, reference=dtrain)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'num_leaves': 64,\n",
    "            'learning_rate': 0.02,\n",
    "            'min_data_in_leaf': 150,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'n_jobs': -1,\n",
    "            'seed': 1024\n",
    "        }\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        dtrain,\n",
    "                        num_boost_round=1000,\n",
    "                        valid_sets=[dtrain, dvalid],\n",
    "                        verbose_eval=50,\n",
    "                        early_stopping_rounds=20)\n",
    "\n",
    "        oof_preds[val_index] = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        test_preds += gbm.predict(X_test, num_iteration=gbm.best_iteration) / kfold.n_splits\n",
    "        gbms.append(gbm)\n",
    "\n",
    "    return gbms, oof_preds, test_preds\n",
    "\n",
    "\n",
    "\n",
    "def train_xgb_kfold(X_train, y_train, X_test, n_fold=5):\n",
    "    '''train xgboost with k-fold split'''\n",
    "    gbms = []\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1024, shuffle=True)\n",
    "    oof_preds = np.zeros((X_train.shape[0],))\n",
    "    test_preds = np.zeros((X_test.shape[0],))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "        logging.info(f'############ fold {fold} ###########')\n",
    "        X_tr, X_val, y_tr, y_val = X_train.iloc[train_index], X_train.iloc[val_index], y_train[train_index], y_train[val_index]\n",
    "        dtrain = xgb.DMatrix(X_tr, y_tr)\n",
    "        dvalid = xgb.DMatrix(X_val, y_val)\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "        params={\n",
    "            'booster':'gbtree',\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': ['logloss', 'auc'],\n",
    "            'max_depth': 8,\n",
    "            'subsample':0.9,\n",
    "            'min_child_weight': 10,\n",
    "            'colsample_bytree':0.85,\n",
    "            'lambda': 10,\n",
    "            'eta': 0.02,\n",
    "            'seed': 1024\n",
    "        }\n",
    "\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'test')]\n",
    "\n",
    "        gbm = xgb.train(params,\n",
    "                        dtrain,\n",
    "                        num_boost_round=1000,\n",
    "                        evals=watchlist,\n",
    "                        verbose_eval=50,\n",
    "                        early_stopping_rounds=20)\n",
    "\n",
    "        oof_preds[val_index] = gbm.predict(dvalid, iteration_range=(0, gbm.best_iteration))\n",
    "        test_preds += gbm.predict(dtest, iteration_range=(0, gbm.best_iteration)) / kfold.n_splits\n",
    "        gbms.append(gbm)\n",
    "\n",
    "    return gbms, oof_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(train, test, feat_cols, label_col, n_fold=10):\n",
    "    '''训练xgboost'''\n",
    "    for col in ['sub_Rate', 'main_Rate', 'outstanding_disburse_ratio']:\n",
    "        train[col] = train[col].apply(lambda x: 1 if x > 1 else x)\n",
    "        test[col] = test[col].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "    X_train = train[feat_cols]\n",
    "    y_train = train[label_col]\n",
    "    X_test = test[feat_cols]\n",
    "    gbms_xgb, oof_preds_xgb, test_preds_xgb = train_xgb_kfold(X_train, y_train, X_test, n_fold=n_fold)\n",
    "\n",
    "    if not os.path.exists('gbms_xgb.pkl'):\n",
    "        save_pkl(gbms_xgb, 'gbms_xgb.pkl')\n",
    "\n",
    "    return gbms_xgb, oof_preds_xgb, test_preds_xgb\n",
    "\n",
    "\n",
    "def train_lgb(train, test, feat_cols, label_col, n_fold=10):\n",
    "    '''训练lightgbm'''\n",
    "    X_train = train[feat_cols]\n",
    "    y_train = train[label_col]\n",
    "    X_test = test[feat_cols]\n",
    "    gbms_lgb, oof_preds_lgb, test_preds_lgb = train_lgb_kfold(X_train, y_train, X_test, n_fold=n_fold)\n",
    "\n",
    "    if not os.path.exists('gbms_lgb.pkl'):\n",
    "        save_pkl(gbms_lgb, 'gbms_lgb.pkl')\n",
    "\n",
    "    return gbms_lgb, oof_preds_lgb, test_preds_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取原始数据集\n",
    "logging.info('data loading...')\n",
    "train = pd.read_csv('auto_train.csv')\n",
    "test = pd.read_csv('auto_test.csv')\n",
    "\n",
    "# 特征工程\n",
    "logging.info('feature generating...')\n",
    "train, test = gen_new_feats(train, test)\n",
    "train, test = gen_target_encoding_feats(train, test, TARGET_ENCODING_FETAS, target_col='loan_default', n_fold=10)\n",
    "train, test = gen_neighbor_feats(train, test)\n",
    "\n",
    "train['asset_cost_bin'] = train['asset_cost_bin'].astype(int)\n",
    "test['asset_cost_bin'] = test['asset_cost_bin'].astype(int)\n",
    "train['loan_to_asset_ratio_bin'] = train['loan_to_asset_ratio_bin'].astype(int)\n",
    "test['loan_to_asset_ratio_bin'] = test['loan_to_asset_ratio_bin'].astype(int)\n",
    "train['asset_cost_bin_mean_target'] = train['asset_cost_bin_mean_target'].astype(float)\n",
    "test['asset_cost_bin_mean_target'] = test['asset_cost_bin_mean_target'].astype(float)\n",
    "\n",
    "# 模型训练：linux和mac的xgboost结果会有些许不同，以模型文件结果为主\n",
    "gbms_xgb, oof_preds_xgb, test_preds_xgb = train_xgb(train.copy(), test.copy(),\n",
    "                                                    feat_cols=SAVE_FEATS,\n",
    "                                                    label_col='loan_default')\n",
    "gbms_lgb, oof_preds_lgb, test_preds_lgb = train_lgb(train, test,\n",
    "                                                    feat_cols=SAVE_FEATS,\n",
    "                                                    label_col='loan_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2、划分阈值\n",
    "因为是0-1二分类，最终分类的均值，可近似理解为取到loan_default=1的概率。 再通过对cv的预测结果排序，取分位数（1-P(loan_default=1)）对应的概率为预测正负样本的划分的临界点。\n",
    "为了让结果更精准，采取小步长遍历临界点附近的点，找到局部最优的概率阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_thres_new(df_train, oof_preds):\n",
    "    df_train['oof_preds'] = oof_preds\n",
    "    # 可看作训练集取到loan_default=1的概率\n",
    "    quantile_point = df_train['loan_default'].mean() \n",
    "    thres = df_train['oof_preds'].quantile(1 - quantile_point) \n",
    "    # 比如 0,1,1,1 mean=0.75 1-mean=0.25,也就是25%分位数取值为0\n",
    "\n",
    "    _thresh = []\n",
    "     #  按照理论阈值的上下0.2范围，0.01步长，找到最佳阈值，f1分数最高对应的阈值即为最佳阈值\n",
    "    for thres_item in np.arange(thres - 0.2, thres + 0.2, 0.01):\n",
    "        _thresh.append(\n",
    "            [thres_item, f1_score(df_train['loan_default'], np.where(oof_preds > thres_item, 1, 0), average='macro')])\n",
    "\n",
    "    _thresh = np.array(_thresh)\n",
    "    best_id = _thresh[:, 1].argmax() # 找到f1最高对应的行\n",
    "    best_thresh = _thresh[best_id][0] # 取出最佳阈值\n",
    "\n",
    "    print(\"阈值: {}\\n训练集的f1: {}\".format(best_thresh, _thresh[best_id][1]))\n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3、模型融合\n",
    "对xgb、lgb的模型cv结果的分位数进行加权求和，再去找融合后的模型0-1的概率阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_thres = gen_thres_new(train, oof_preds_xgb)\n",
    "lgb_thres =  gen_thres_new(train, oof_preds_lgb)\n",
    "\n",
    "\n",
    "# 结果聚合\n",
    "df_oof_res = pd.DataFrame({'customer_id': train['customer_id'],\n",
    "                            'loan_default':train['loan_default'],\n",
    "                            'oof_preds_xgb': oof_preds_xgb,\n",
    "                            'oof_preds_lgb': oof_preds_lgb})\n",
    "\n",
    "# 模型融合\n",
    "df_oof_res['xgb_rank'] = df_oof_res['oof_preds_xgb'].rank(pct=True) # percentile rank,返回的是排序后的分位数\n",
    "df_oof_res['lgb_rank'] = df_oof_res['oof_preds_lgb'].rank(pct=True)\n",
    "\n",
    "df_oof_res['preds'] = 0.31 * df_oof_res['xgb_rank'] + 0.69 * df_oof_res['lgb_rank']\n",
    "\n",
    "# 融合后的模型，概率阈值\n",
    "thres = gen_thres_new(df_oof_res, df_oof_res['preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 预测\n",
    "按照融模后训练集的概率阈值，对测试集预测结果进行0-1划分，输出最终预测提交结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_submit_file(df_test, test_preds, thres, save_path):\n",
    "    # 按最终模型融合后的阈值进行划分\n",
    "    df_test['test_preds_binary'] = np.where(test_preds > thres, 1, 0)  \n",
    "    df_test_submit = df_test[['customer_id', 'test_preds_binary']]\n",
    "    df_test_submit.columns = ['customer_id', 'loan_default']\n",
    "    print(f'saving result to: {save_path}')\n",
    "    df_test_submit.to_csv(save_path, index=False)\n",
    "    print('done!')\n",
    "    return df_test_submit\n",
    "\n",
    "\n",
    "\n",
    "df_test_res = pd.DataFrame({'customer_id': test['customer_id'],\n",
    "                                'test_preds_xgb': test_preds_xgb,\n",
    "                                'test_preds_lgb': test_preds_lgb})\n",
    "\n",
    "df_test_res['xgb_rank'] = df_test_res['test_preds_xgb'].rank(pct=True)\n",
    "df_test_res['lgb_rank'] = df_test_res['test_preds_lgb'].rank(pct=True)\n",
    "df_test_res['preds'] = 0.31 * df_test_res['xgb_rank'] + 0.69 * df_test_res['lgb_rank']\n",
    "\n",
    "# 结果产出\n",
    "df_submit = gen_submit_file(df_test_res, df_test_res['preds'], thres,\n",
    "                            save_path='result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
